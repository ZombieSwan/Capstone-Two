{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b53e67",
   "metadata": {},
   "source": [
    "## Predicting IPO Excess Returns: A Sentiment Analysis Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6d273",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a969de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6bf43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id           writer   post_date  \\\n",
      "0  550441509175443456  VisualStockRSRC  1420070457   \n",
      "1  550441672312512512      KeralaGuy77  1420070496   \n",
      "2  550441732014223360      DozenStocks  1420070510   \n",
      "3  550442977802207232     ShowDreamCar  1420070807   \n",
      "4  550443807834402816     i_Know_First  1420071005   \n",
      "\n",
      "                                                body  comment_num  \\\n",
      "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
      "1  Insanity of today weirdo massive selling. $aap...            0   \n",
      "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
      "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
      "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
      "\n",
      "   retweet_num  like_num  \n",
      "0            0         1  \n",
      "1            0         0  \n",
      "2            0         0  \n",
      "3            0         1  \n",
      "4            0         1  \n",
      "             tweet_id ticker_symbol\n",
      "0  550803612197457920          AAPL\n",
      "1  550803610825928706          AAPL\n",
      "2  550803225113157632          AAPL\n",
      "3  550802957370159104          AAPL\n",
      "4  550802855129382912          AAPL\n"
     ]
    }
   ],
   "source": [
    "tweet_filepath = r'C:\\Users\\restr\\Documents\\Springboard\\Capstone project 2\\IPO Project\\Tweet.csv'\n",
    "company_tweet_filepath = r'C:\\Users\\restr\\Documents\\Springboard\\Capstone project 2\\IPO Project\\Company_Tweet.csv'\n",
    "\n",
    "\n",
    "df_tweet = pd.read_csv(tweet_filepath)\n",
    "df_company_tweet = pd.read_csv(company_tweet_filepath)\n",
    "\n",
    "# Display the first few rows of the dataframes\n",
    "print(df_tweet.head())\n",
    "print(df_company_tweet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73832f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_tweet shape: (3717964, 7)\n",
      "df_company_tweet shape: (4336445, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3717964 entries, 0 to 3717963\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   tweet_id     int64 \n",
      " 1   writer       object\n",
      " 2   post_date    int64 \n",
      " 3   body         object\n",
      " 4   comment_num  int64 \n",
      " 5   retweet_num  int64 \n",
      " 6   like_num     int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 198.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4336445 entries, 0 to 4336444\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   tweet_id       int64 \n",
      " 1   ticker_symbol  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 66.2+ MB\n",
      "None\n",
      "           tweet_id     post_date   comment_num   retweet_num      like_num\n",
      "count  3.717964e+06  3.717964e+06  3.717964e+06  3.717964e+06  3.717964e+06\n",
      "mean   8.797444e+17  1.498582e+09  3.123642e-01  6.214807e-01  2.219982e+00\n",
      "std    1.924039e+17  4.587266e+07  1.966064e+00  7.009571e+00  1.429093e+01\n",
      "min    5.504415e+17  1.420070e+09  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "25%    7.169886e+17  1.459778e+09  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "50%    8.743180e+17  1.497289e+09  0.000000e+00  0.000000e+00  0.000000e+00\n",
      "75%    1.050771e+18  1.539358e+09  0.000000e+00  0.000000e+00  1.000000e+00\n",
      "max    1.212160e+18  1.577837e+09  6.310000e+02  9.990000e+02  9.990000e+02\n",
      "           tweet_id\n",
      "count  4.336445e+06\n",
      "mean   8.834282e+17\n",
      "std    1.927735e+17\n",
      "min    5.504415e+17\n",
      "25%    7.185450e+17\n",
      "50%    8.825934e+17\n",
      "75%    1.054776e+18\n",
      "max    1.212160e+18\n"
     ]
    }
   ],
   "source": [
    "# Show the shape of the dataframes\n",
    "print('df_tweet shape:', df_tweet.shape)\n",
    "print('df_company_tweet shape:', df_company_tweet.shape)\n",
    "\n",
    "# Show general information about the dataframes\n",
    "print(df_tweet.info())\n",
    "print(df_company_tweet.info())\n",
    "\n",
    "# Show descriptive statistics of the dataframes\n",
    "print(df_tweet.describe())\n",
    "print(df_company_tweet.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43dccbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id           0\n",
      "writer         47273\n",
      "post_date          0\n",
      "body               0\n",
      "comment_num        0\n",
      "retweet_num        0\n",
      "like_num           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12d37fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id         0\n",
      "ticker_symbol    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_company_tweet.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7bf5dc",
   "metadata": {},
   "source": [
    "Convert the post_date from UNIX timestamp to standard datetime format and then merge the dataframes besed on 'tweet_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15225e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweet['post_date'] = pd.to_datetime(df_tweet['post_date'], unit='s')\n",
    "\n",
    "df = pd.merge(df_tweet, df_company_tweet, how='inner', on='tweet_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713b20c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id           writer           post_date  \\\n",
      "0  550441509175443456  VisualStockRSRC 2015-01-01 00:00:57   \n",
      "1  550441672312512512      KeralaGuy77 2015-01-01 00:01:36   \n",
      "2  550441732014223360      DozenStocks 2015-01-01 00:01:50   \n",
      "3  550442977802207232     ShowDreamCar 2015-01-01 00:06:47   \n",
      "4  550443807834402816     i_Know_First 2015-01-01 00:10:05   \n",
      "\n",
      "                                                body  comment_num  \\\n",
      "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
      "1  Insanity of today weirdo massive selling. $aap...            0   \n",
      "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
      "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
      "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
      "\n",
      "   retweet_num  like_num ticker_symbol  \n",
      "0            0         1          AAPL  \n",
      "1            0         0          AAPL  \n",
      "2            0         0          AMZN  \n",
      "3            0         1          TSLA  \n",
      "4            0         1          AAPL  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88ddce",
   "metadata": {},
   "source": [
    "Filter data from 2018 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4732f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tweet_id           writer           post_date  \\\n",
      "2516889  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516890  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516891  947618475958325248  ExactOptionPick 2018-01-01 00:00:25   \n",
      "2516892  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "2516893  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "\n",
      "                                                      body  comment_num  \\\n",
      "2516889  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516890  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516891  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
      "2516892  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "2516893  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "\n",
      "         retweet_num  like_num ticker_symbol  \n",
      "2516889            0         2         GOOGL  \n",
      "2516890            0         2          AMZN  \n",
      "2516891            0         0         GOOGL  \n",
      "2516892            0         0          AAPL  \n",
      "2516893            0         0          AMZN  \n"
     ]
    }
   ],
   "source": [
    "df['post_date'] = pd.to_datetime(df['post_date'])\n",
    "\n",
    "df = df[df['post_date'].dt.year >= 2018]\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419133e7",
   "metadata": {},
   "source": [
    "## Sentiment Analysis \n",
    "To perform our Sentiment Analysis, first we will use TextBlob. It is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, and sentiment analysis.\n",
    "\n",
    "The sentiment analysis algorithm used by TextBlob is based on a machine learning approach and uses a pre-trained Naive Bayes classifier.\n",
    "\n",
    "The function will return two columns: \n",
    "\n",
    "Polarity: This is a value that ranges from -1 to 1. Values closer to 1 mean that the statement is positive, values closer to -1 mean that the statement is negative, and values around 0 are neutral.\n",
    "\n",
    "Subjectivity: This is a value that ranges from 0 to 1. Values closer to 1 are more subjective (based on or influenced by personal feelings, tastes, or opinions), and values closer to 0 are more objective (not influenced by personal feelings or opinions in considering and representing facts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e86f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tweet_id           writer           post_date  \\\n",
      "2516889  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516890  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516891  947618475958325248  ExactOptionPick 2018-01-01 00:00:25   \n",
      "2516892  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "2516893  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "\n",
      "                                                      body  comment_num  \\\n",
      "2516889  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516890  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516891  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
      "2516892  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "2516893  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "\n",
      "         retweet_num  like_num ticker_symbol  sentiment  \n",
      "2516889            0         2         GOOGL        1.0  \n",
      "2516890            0         2          AMZN        1.0  \n",
      "2516891            0         0         GOOGL        0.2  \n",
      "2516892            0         0          AAPL        0.5  \n",
      "2516893            0         0          AMZN        0.5  \n"
     ]
    }
   ],
   "source": [
    "# Function to get the polarity of text\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df['sentiment'] = df['body'].apply(get_polarity)\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c273892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tweet_id           writer           post_date  \\\n",
      "2516889  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516890  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516891  947618475958325248  ExactOptionPick 2018-01-01 00:00:25   \n",
      "2516892  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "2516893  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "\n",
      "                                                      body  comment_num  \\\n",
      "2516889  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516890  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516891  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
      "2516892  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "2516893  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "\n",
      "         retweet_num  like_num ticker_symbol  sentiment  subjectivity  \n",
      "2516889            0         2         GOOGL        1.0           1.0  \n",
      "2516890            0         2          AMZN        1.0           1.0  \n",
      "2516891            0         0         GOOGL        0.2           0.4  \n",
      "2516892            0         0          AAPL        0.5           0.6  \n",
      "2516893            0         0          AMZN        0.5           0.6  \n"
     ]
    }
   ],
   "source": [
    "# Function to get the subjectivity of text\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "df['subjectivity'] = df['body'].apply(get_subjectivity)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000a9af",
   "metadata": {},
   "source": [
    "## VADER\n",
    "Now we will use VADER, a lexicon and rule-based sentiment analysis tool specifically attuned to sentiments expressed in social media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da9513dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tweet_id           writer           post_date  \\\n",
      "2516889  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516890  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516891  947618475958325248  ExactOptionPick 2018-01-01 00:00:25   \n",
      "2516892  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "2516893  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "\n",
      "                                                      body  comment_num  \\\n",
      "2516889  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516890  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516891  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
      "2516892  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "2516893  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "\n",
      "         retweet_num  like_num ticker_symbol  sentiment  subjectivity  \\\n",
      "2516889            0         2         GOOGL        1.0           1.0   \n",
      "2516890            0         2          AMZN        1.0           1.0   \n",
      "2516891            0         0         GOOGL        0.2           0.4   \n",
      "2516892            0         0          AAPL        0.5           0.6   \n",
      "2516893            0         0          AMZN        0.5           0.6   \n",
      "\n",
      "                                          sentiment_scores  \n",
      "2516889  {'neg': 0.0, 'neu': 0.861, 'pos': 0.139, 'comp...  \n",
      "2516890  {'neg': 0.0, 'neu': 0.861, 'pos': 0.139, 'comp...  \n",
      "2516891  {'neg': 0.0, 'neu': 0.695, 'pos': 0.305, 'comp...  \n",
      "2516892  {'neg': 0.0, 'neu': 0.811, 'pos': 0.189, 'comp...  \n",
      "2516893  {'neg': 0.0, 'neu': 0.811, 'pos': 0.189, 'comp...  \n"
     ]
    }
   ],
   "source": [
    "# Create a SentimentIntensityAnalyzer object\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to get the sentiment scores \n",
    "def get_sentiment_scores(text):\n",
    "    return sid.polarity_scores(text)\n",
    "\n",
    "df['sentiment_scores'] = df['body'].apply(get_sentiment_scores)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d5ce0",
   "metadata": {},
   "source": [
    "This returns a new column 'sentiment_scores' which is a dictionary that contains four values:\n",
    "\n",
    "'neg': Negative sentiment in text\n",
    "\n",
    "'neu': Neutral sentiment in text\n",
    "\n",
    "'pos': Positive sentiment in text\n",
    "\n",
    "'compound': Compound (i.e., aggregated) sentiment score, which is a weighted composite score computed by summing the valence scores of each word in the lexicon, adjusted for the impact of intensifiers, negations, and degree adverbs, then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single measure of sentiment.\n",
    "\n",
    "Now we create separate columns for these scores as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfef6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop(['sentiment_scores'], axis=1), df['sentiment_scores'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73be1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tweet_id           writer           post_date  \\\n",
      "2516889  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516890  947618374569353216          Auscomp 2018-01-01 00:00:01   \n",
      "2516891  947618475958325248  ExactOptionPick 2018-01-01 00:00:25   \n",
      "2516892  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "2516893  947619846124122113          Eric714 2018-01-01 00:05:51   \n",
      "\n",
      "                                                      body  comment_num  \\\n",
      "2516889  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516890  The 7 Greatest Tech Stocks of All Time monitor...            0   \n",
      "2516891  Don't miss our next FREE OPTION TRADE.  Sign u...            0   \n",
      "2516892  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "2516893  How is $AAPL @Apple going to get me to buy a #...            1   \n",
      "\n",
      "         retweet_num  like_num ticker_symbol  sentiment  subjectivity  neg  \\\n",
      "2516889            0         2         GOOGL        1.0           1.0  0.0   \n",
      "2516890            0         2          AMZN        1.0           1.0  0.0   \n",
      "2516891            0         0         GOOGL        0.2           0.4  0.0   \n",
      "2516892            0         0          AAPL        0.5           0.6  0.0   \n",
      "2516893            0         0          AMZN        0.5           0.6  0.0   \n",
      "\n",
      "           neu    pos  compound  \n",
      "2516889  0.861  0.139    0.6369  \n",
      "2516890  0.861  0.139    0.6369  \n",
      "2516891  0.695  0.305    0.8306  \n",
      "2516892  0.811  0.189    0.6369  \n",
      "2516893  0.811  0.189    0.6369  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2bc7e",
   "metadata": {},
   "source": [
    "### Save as CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e831f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf7ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
